---
layout: ../../layouts/MarkdownLayout.astro
title: Does Technology Create a Freer Society?
date: 2026-01-13
---

# Does Technology Create a Freer Society?

Tags: `economic` `platform` `agency` Â· ðŸª‘ armchair

Explores how platform economics and semantic capture undermine economic freedom. Argues that consumer choice is no longer a reliable proxy for agency when platforms control the language of exchange.

---

While FTX was a particularly egregious example of a company optimizing for growth over fidelity, the more pernicious threat lies in the _unintentional_ erosion of the contract between consenting parties. The increasing reliance on ill-defined metrics and terminologiesâ€”"creditworthiness," "service rating," "community standards"â€”to justify the assortment of users on platforms gives these platforms undue leverage over the lives of their users.

## The Economy of Obfuscation

We are living in what I call an "economy of obfuscation." Platforms have discovered that ambiguity is profitable. When terms remain undefined or selectively defined, accountability evaporates. A user banned for violating "community guidelines" has no recourse because they cannot point to what specific action crossed what specific line. The platform reserves the right to interpret its own language, and the user consents to this asymmetry the moment they click "I agree."

This isn't merely inconvenientâ€”it represents a fundamental shift in how economic power operates. Traditional market failures assume that both parties understand the terms of exchange. But what happens when one party controls not just the exchange, but the very language in which it occurs?

## Semantic Capture and Soft Power

The Uber example is not unique. The fact that the company controls the very language of the exchange signals the emergence of a new form of economic soft powerâ€”one where the definition of each term favors the platform, displacing previously ad-hoc mutual understanding between human beings.

A "surge cost" may have once implied a mutual agreement to shift the burden of extra gas between a taxi driver and a passenger during heavy traffic, open for negotiation. In the context of a platform, it becomes a license for opaque rent-seeking:

1. Drivers gave explicit consent to these pricing mechanisms without any possibility of understanding the intricacies of the algorithm upon which they now stake their income, and
2. Even if they understood the algorithm, they would have no meaningful recourseâ€”the overwhelmingly pro-consumer regulatory environment leaves platform workers without leverage, forcing them to adopt platform terminology simply to remain competitive, as with the now-standard term "ride-hailing service."

Beyond ride-sharing, consider credit scoring. "Creditworthiness" sounds objective, almost scientific. But the algorithms that compute it incorporate variables that borrowers cannot see, weight factors they cannot challenge, and update in ways they cannot anticipate. A person denied a loan for "insufficient creditworthiness" is told nothing about what specific behavior or circumstance led to that judgment. The term performs objectivity while obscuring arbitrary power.

Content moderation follows the same pattern. "Harmful content" and "misinformation" are defined retroactively and inconsistently. Creators build livelihoods on platforms only to find their content demonetized or removed based on criteria that shift without notice. The language sounds reasonableâ€”who could oppose removing "harmful" content?â€”but the platform retains sole authority to determine what the words mean.

## The Blurring of Consumer and Laborer

As platform economics expands, the distinction between consumers and laborers becomes increasingly blurred. The gig worker is simultaneously a service provider and a productâ€”rated, ranked, and optimized like any other input. The social media user is both audience and content creator, generating value while consuming it. Traditional economic categories fail to capture these hybrid roles.

This matters because our frameworks for economic freedom were built around clearer distinctions. Consumer protection law assumes the consumer is a buyer, not a seller. Labor law assumes the worker has an employer, not an algorithm. When a single individual occupies multiple roles simultaneouslyâ€”and when those roles are defined by platform-controlled terminologyâ€”who exactly is being protected?

Is consumer choice actually a good proxy for economic freedom in the information age? The question becomes pressing when the chooser cannot understand the terms of the choice, when the alternatives are equally opaque, and when the act of choosing generates data that further entrenches the platform's advantage.

## Toward an Inferentialist Critique

The representationalist framework of economics cannot easily account for what I call "feasibility space engineering"â€”the combination of black-box algorithms and vague language that manufactures consent without meaningful understanding. Classical economics treats language as transparent: words represent things, and rational actors can evaluate what those things are worth. But this model breaks down when words mean different things to different parties by design.

Robert Brandom's inferentialist framework offers a different approach. Rather than asking what terms represent, we ask what inferences they license. When a platform declares a user "ineligible" for a benefit, what follows? What can the user do, say, or demand in response? If the answer is "nothing"â€”if the term licenses no inferences that empower the userâ€”then the appearance of meaningful language masks a unilateral exercise of power.

The structural and semantic alignment gap between platforms and their participants is widening. Whether driven by the pressure to expand market share or satisfy investors, the compulsion to penetrate every vertical of the economy means this gulf between consumer choice and economic freedom will only grow. Through the intersection of engineering, economics, and linguistics, a new critical vocabulary of the information age becomes necessary.

Systems should preserve agency. Incentives shouldn't hide behind ambiguity. Engineering must be correct, auditable, and aligned with what's promised to users. If we take these principles seriously, we might yet recover the vision of technology empowering the little ones rather than optimizing them.

---

**Connected thoughts:**
- Inference Replaces Representation
- Metrics Become Territory

**Theoretical grounding:**
- Brandom's inferentialism
- Platform economics literature
- Schrepel on algorithmic power
